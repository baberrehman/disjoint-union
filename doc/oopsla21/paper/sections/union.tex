\section{The Union Calculus (\name)}
\label{sec:union}
\bruno{Baber, look for cite in latex and fill in the missing references: there are a few.}

This section introduces the union calculus \name. The distinctive feature
of the \name calculus is a type-based switch expression with disjoint
cases, which can be used to eliminate values with union types.
%Such type-based
%switch expression is inspired by a similar construct in the Ceylon programming
%language.
We adapt the notion of disjointness from previous work on
\emph{disjoint intersection types}~\cite{oliveira2016disjoint} to \name, and show that \name is type
sound and deterministic.

%%%%%%%%%%%%%%%%%%%%%
%% Syntax
%%%%%%%%%%%%%%%%%%%%%

\subsection{Syntax}\label{sec:union:syntax}
\Cref{fig:union:syntax} shows the syntax for \cal. Metavariables
$[[A]]$, $[[B]]$ and $[[C]]$ range over types.  Types include top ($[[Top]]$),
bottom ($[[Bot]]$), function ($[[A -> B]]$) and union ($[[A \/ B]]$)
types. Metavariable $[[e]]$ ranges over program
expressions. Expressions include variables ($[[x]]$), integers
($[[i]]$), type annotations ($[[e:A]]$), lambda abstractions
($[[\x.e]]$), applications ($[[e1 e2]]$) and a novel switch ($[[switch
    e A e1 B e2]]$) expression. The \emph{switch} expression is a case
expression and evaluates a specific branch by matching the
type.
%Details of \typeof expression will further be discussed in typing
%and operational semantics sections.

\ningning{We need to cite \citet{Huang:typedirected} somewhere. Do we need to do
  it in the overview? I added the citation here. Maybe will also add it in the
  operational semantics section.}

\paragraph{Values, pre-values and annotated values}

In \name there are two kinds of values ($[[v]]$): annotated values $[[w]]$; and unannotated
lambda expressions ($[[\x.e]]$). In annotated values, which have the form $[[p
:A]]$, the type annotation $[[A]]$ represents the \textit{dynamic type} that the
value has at runtime.
%We divide the representation for values into three parts: pre-values,
%annotated values and values.
Metavariable $[[p]]$ ranges over pre-values. Pre-values
consist of integers $[[i]]$
and annotated lambda expressions $[[\x.e : A -> B]]$.
%Annotated values are pre-values with an additional type annotation i.e. $[[p:A]]$.
It is important to note that $[[i]]$ is not a value in this
calculus, instead $[[i:Int]]$ or $[[i:Top]]$ are values.
We have unannotated lambda expressions ($[[\x.e]]$) as values, as
\name employs bi-directional type-checking, where
unannotated lambda expressions can be arguments of functions, and
may appear as a result of reducing such arguments.
Annotated lambda values have two annotations;
that is, $[[\x.e : A -> B : C]]$ is a value.
As already mentioned, $C$ is the dynamic type of the value
at runtime, whereas $[[A -> B]]$ is the original \emph{static type} of the lambda.
As we will see, the distinguish between dynamic and static
types is important for the \textit{type-directed operational semantics}
\cite{Huang:typedirected}.
For readers familiar with calculi with gradual types~\cite{}, the two annotations
can be also be understood as the \emph{source type} and \emph{target type}
of an upcast: i.e. if the value is well-typed we have that $[[A -> B]] <: [[C]]$.

Finally, a context ($[[G]]$) maps variables to their associated types. A typing
mode ($[[dirflag]]$), as in traditional bi-directional type checking, can either be the
inference mode ($[[=>]]$) or the checking mode ($[[<=]]$).

\begin{figure}[t]
  \begin{small}
    \centering
    \begin{tabular}{lrcl} \toprule
      Types & $[[A]], [[B]]$, $[[C]]$ & $\Coloneqq$ & $ [[Top]] \mid [[Bot]] \mid [[Int]] \mid [[A -> B]] \mid [[A \/ B]] $ \\
      Expr & $[[e]]$ & $\Coloneqq$ & $[[x]] \mid [[i]] \mid [[e:A]] \mid [[\x.e]] \mid [[e1 e2]] \mid [[switch e A e1 B e2]]$\\
      PValue & $[[p]]$ & $\Coloneqq$ & $[[i]] \mid [[\x.e : A -> B]] $\\
      AValue & $[[w]]$ & $\Coloneqq$ & $[[p:A]]$\\
      Value & $[[v]]$ & $\Coloneqq$ & $[[w]] \mid [[\x.e]] $\\
      Context & $[[G]]$ & $\Coloneqq$ & $ \cdot \mid [[G , x : A]]$ \\
      Mode & $[[dirflag]]$ & $\Coloneqq$ & $[[=>]] \ \mid \ [[<=]]$ \\
      \bottomrule
    \end{tabular}
  \end{small}
  \begin{small}
    \centering
    \drules[s]{$ [[A <: B ]] $}{Subtyping}{top, bot, int, arrow, ora, orb, orc}
  \end{small}

  \ningning{I still think we should remove the word ``algorithmic'' in
    ``algorithmic subtyping'' in the caption. So I did.}

  \caption{Syntax and Subtyping for \cal.}
  \label{fig:union:syntax}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%
%% Subtyping
%%%%%%%%%%%%%%%%%%%%%
\subsection{Subtyping}
\label{sec:union:sub}
The subtyping rules for \cal are shown in
\Cref{fig:union:syntax}. Most rules are standard.
\Rref{s-top} states that all types are subtypes of
the $[[Top]]$ type. \Rref{s-bot} states that $[[Bot]]$ type is subtype of
all types. \Rref{s-int, s-arrow} are standard rules for integers and
functions respectively.  Functions are contravariant in input types
and covariant in output types. \Rref{s-ora,s-orb,s-orc} deal with
subtyping for union types. \rref{s-ora} says that the union type of two types $[[A1]]$ and $[[A2]]$
is a subtype of another type $[[A]]$ if both $[[A1]]$ and $[[A2]]$ are subtypes of
$[[A]]$. \Rref{s-orb,s-orc} state that if a
type is subtype of one of the components of a union type, then it is subtype of whole
union type.  
\snow{The link for s-orc is lost. Maybe we need to use ``and \rref{s-orc}" instead? Can we use $B$ instead of $A$ in the three union rules to make them
more readable?}
\ningning{This can be fixed by not putting extra space between rules or
  otherwise it will break the hyperlinks. Baber can you fix other ones? There
  are quite a few.}

The subtyping relation for \cal is reflexive and transitive.
\begin{lemma}[Subtyping Reflexivity]
  $[[A <: A]]$.
\label{lemma:union:refl}
\end{lemma}
\begin{comment}
\begin{proof}
  By induction on type A. All cases are trivial to prove.
\end{proof}
\end{comment}
\begin{lemma}[Subtyping Transitivity]
  If \ $[[A <: B]]$ \ and \ $[[B <: C]]$ \ then \ $[[A <: C]]$.
  \label{lemma:union:trans}
\end{lemma}
\begin{comment}
\begin{proof}
  By induction on type B.
  \begin{itemize}
    \item Cases $[[Top]]$, $[[Bot]]$ and $[[Int]]$ are trivial to prove.
    \item Case $[[A -> B]]$ requires double induction on type $[[C]]$
          and $[[A]]$.
    \item Case $[[A \/ B]]$ requires \Cref{lemma:union:sub-or}
  \end{itemize}
\end{proof}\bruno{If space is a concern we can probably drop the lemma statements
for reflexivity and transitivity as these are quite standard.}

\begin{lemma}[Subtyping Union Inversion]
\label{lemma:union:sub-or}
  If \ $[[A \/ B <: C]]$ then:
  \begin{enumerate}
    \item $[[A <: C]]$ and
    \item $[[B <: C]]$
  \end{enumerate}
\end{lemma}
\end{comment}


%%%%%%%%%%%%%%%%%%%%%%%
%% Disjointness
%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Disjointness}
\label{sec:union:disj}
Now we turn to the notion of disjointness for
union types and case expression for \cal. In essence, disjointness for \cal is
the dual to the disjointness notion in $\lambda_i$~\cite{oliveira2016disjoint},
a calculus with disjoint intersection types.
In $\lambda_i$, two
types in are disjoint if they do not share any common
\emph{supertype} which is not \emph{top-like} (i.e., isomorphic to the top type). Dually, in
\cal, two types are disjoint if they do not share any common \emph{subtype} which
is not \emph{bottom-like}.
\bruno{In the overview section we need to talk about more about this and
explain that common subtypes are important for the switch expression.}
We emphasize the significance of
\emph{supertypes} and \emph{subtypes} in $\lambda_i$ and \cal
respectively.

\paragraph{Bottom-Like Types}
\emph{Bottom-like} types are types that are isomorphic (i.e.
both supertypes and subtypes) of the bottom type $\bot$. Therefore
any bottom-like types behave like the $[[Bot]]$ type.
In \name, there
are infinitely many such types, including, for example $\bot \lor \bot$,
$\bot \lor \bot \lor \bot$, as well as $\bot$ itself. Bottom-like types
are important because they allow us to define disjointness.
%are integral part of disjoitness in \cal like
%\emph{top-like} in $\lambda_i$ \cite{oliveira2016disjoint}. Therefore,
%it is important to understand the notion of \emph{bottom-like} types
%before diving into the details of disjointness.

An inductive definition that captures all the bottom-like types
is shown at the top of \Cref{fig:union:disj-typ}.
Type $[[Bot]]$ is obviously a \emph{bottom-like} type
(\rref{bl-bot}), and a union type of two \emph{bottom-like} types is also
a \emph{bottom-like} type (\rref{bl-or}).  It is trivial to conclude
that a union type is \emph{bottom-like} only if all the 
types in union are $[[Bot]]$. The correctness of our definition for
bottom-like types is established by the following properties:
\snow{Why we need an extra definition for bottom-like rather than
directly using ``A<:Bot"? And the notation overlaps with the
DynamicType function later.}
\ningning{It's just nice to have a standalone and inductive definition I think.}
\ningning{And yes, Baber, please fix the notation. Maybe use $\lceil this
  \rceil$  and $\lfloor this \rfloor$ for later functions? Or use one of them
  for disjointness.  }

\begin{lemma}[Bottom-Like Soundness]
  If \ $[[botlike A]]$ \ then \ $[[A <: B]]$.
\label{lemma:union:bl-soundness}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on bottom-like relation.
  \begin{itemize}
    \item All cases are trivial to prove.
  \end{itemize}
\end{proof}
\end{comment}

\begin{lemma}[Bottom-Like Completeness]
  If \ $[[A <: Bot]]$ \ then \ $[[botlike A]]$.
\label{lemma:union:bl-completeness}
\end{lemma}

\noindent The soundness lemma states that if a type is bottom-like, then it is
a subtype of any other type (and, in particular, it is a subtype of $[[Bot]]$).
The completeness lemma states that if $[[A]]$ is a subtype of $[[Bot]]$ then $A$
is bottom-like.

\begin{comment}
\begin{proof}
  By induction on type $[[A]]$.
  \begin{itemize}
    \item Cases $[[Top]]$, $[[Bot]]$, $[[Int]]$ and $[[A -> B]]$ are trivial to prove.
    \item Case $[[A \/ B]]$ requires \Cref{lemma:union:sub-or}.
  \end{itemize}
\end{proof}
\end{comment}

\paragraph{Declarative Disjointness}
Now we present
the declarative definition for disjointness as follows.
%Recall that two types in \cal are disjoint if they do not share any common subtype which is not
%\emph{bottom-like}. The formal definition of disjoint specifications for this calculus is:

\begin{definition}
  A $*_s$ B $\Coloneqq$ $\forall$ C, $[[C <: A]]$ $\wedge$ $[[C <: B]]$ $\rightarrow$ $[[botlike C]]$
\label{def:union:disj}
\end{definition}

\noindent That is, two types are disjoint if all their common subtypes are bottom-like.
\begin{comment}
With this definition we have that different primitive types are disjoint. For example
$[[Int]] * [[Bool]]$ since the only common subtypes of $[[Int]]$ and $[[Bool]]$
are bottom-like. A more interesting case is the disjointness of two function types.
It turns out that function types are never disjoint, since we can always find
a common subtype for any two function types. For example, if we have $[[Int -> Bool]]$
and $[[String -> Char]]$ then a common subtype that is not bottom-like is
$[[Top -> Bot]]$. Therefore, $[[Int -> Bool]]$ and $[[String -> Char]]$ are not
disjoint.

\noindent Reader may think at this point that $[[Bot]]$ type can simply be used in \Cref{def:union:disj}
instead of $[[botlike C]]$ in the conclusion. Answer to this question is
union type with $[[Bot]]$ as all primitive types is also a least subtype in \cal.
$[[botlike C]]$ also handles this case.
\end{comment}
We illustrate this definition with a few examples:

\begin{enumerate}
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Int -> Bool]]:}$ \\
        $[[Int]]$ and $[[Int -> Bool]]$ are disjoint types. All common subtypes of $[[Int]]$ and $[[A -> B]]$ are bottom-like types,
        including $[[Bot]]$ and unions of $[[Bot]]$ types.
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Bot]]:}$ \\
    $[[Int]]$ and $[[Bot]]$ are disjoint types, since again all common subtypes are bottom-like. In general, the type $[[Bot]]$ (or any other bottom-like type)
    is disjoint to any other type.
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Int]]:}$ \\
        $[[Int]]$ and $[[Int]]$ are not disjoint types because they share a common subtype $[[Int]]$ which
        is not \emph{bottom-like}. In general, one type is not disjoint with
        itself, unless it is bottom-like.
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Top]]:}$ \\
        $[[Int]]$ and $[[Top]]$ are not disjoint types because they share a common
    subtype $[[Int]]$ which is not \emph{bottom-like}. In general no type
    is disjoint to $[[Top]]$, except for bottom-like types.
  \item $\boldsymbol{A = [[Int -> Bool]], \ B = \ [[String -> Char]]:}$
    The types $[[Int -> Bool]]$ and $[[String -> Char]]$ are not disjoint,
    since we can find non-bottom-like types that are subtypes
    of both types. For instance $[[Top -> Bot]]$ is a subtype of both types.
    More generally, any two function types can never be disjoint: it is always
    possible to find a common subtype, which is not bottom-like.
    \\
\end{enumerate}
\snow{I like the idea to use examples here. Can we have one or two with union types
involved as well?}
\ningning{I agree. Actually that's important. That's what's special about this
  system. Baber can you do that? Adding one or two examples would be enough.}

\begin{comment}
\begin{figure}[t]
  \begin{small}
    \centering
    \drules[ad]{$[[A * B]]$}{Algorithmic Disjointness}{btmr, btml, intl, intr, orl, orr}
  \end{small}
  \caption{Algorithmic Disjointness for \cal.}
  \label{fig:union:ad}
\end{figure}
\end{comment}

\paragraph{Algorithmic Disjointness}
The middle part of \Cref{fig:union:disj-typ} shows an algorithmic
version of disjointness.  \Rref{ad-btmr, ad-btml} state that the $[[Bot]]$
type is disjoint to all types.  \Rref{ad-intl, ad-intr} state that
$[[Int]]$ and $[[A -> B]]$ are disjoint types.  Algorithmic
disjointness can further be scaled to more primitive disjoint types
such as $Bool$ and $String$ by adding more rules similar to
\rref{ad-intl, intr} for additional primitive types.  \Rref{ad-orl,
  ad-orr} are two symmetric rules for union types. Any type $[[C]]$ is
disjoint to an union type $[[A \/ B]]$ if $[[C]]$ is disjoint to both
$[[A]]$ and $[[B]]$.

We show that algorithmic disjointness is sound and complete
with respect to its declarative specification (\Cref{def:union:disj}).
% , and disjointness is a symmetric relation.
% The following lemmas summarize key properties of disjointness.

\begin{lemma}[Disjointness Soundness]
  If \ $[[A * B]]$ \ then \ $[[A *s B]]$.
\label{lemma:union:disj-sound}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on algorithmic disjointness relation.
  \begin{itemize}
    \item Cases \rref{ad-btmr, ad-btml, ad-orl, ad-orr} require induction on hypothesis
          and \Cref{lemma:union:sub-or}.
    \item Cases \rref{ad-intl, ad-intr} require induction on type and \Cref{lemma:union:sub-or}.
  \end{itemize}
\end{proof}
\end{comment}

\begin{lemma}[Disjointness Completeness]
  If \ $[[A *s B]]$ \ then \ $[[A * B]]$.
\label{lemma:union:disj-complete}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on type A.
  \begin{itemize}
    \item Case $[[Top]]$ requires \Cref{lemma:union:bl-disj}.
    \item Case $[[Bot]]$ is trivial to prove.
    \item Case $[[Int]]$ requires induction on type B and
          \Cref{lemma:union:bl-disj,lemma:union:disj-sym}.
    \item Case $[[A -> B]]$ requires induction on type B and \Cref{lemma:union:disj-sym}.
    \item Case $[[A \/ B]]$ follows directly from inductive hypothesis.
  \end{itemize}
\end{proof}
\end{comment}

\ningning{Why this one here? I think we can show it for the declarative
  definition. Then the following one follows from soundness and completeness.}

\begin{lemma}[Bottom-Like Disjoint]
  If \ $[[botlike A]]$ \ then \ $[[A * B]]$.
\label{lemma:union:bl-disjoint}
\end{lemma}

\ningning{I removed the symmetry lemma as it's too obvious from the rules..}

% \begin{lemma}[Disjointness Symmetry]
%   If \ $[[A * B]]$ \ then \ $[[B * A]]$.
% \label{lemma:union:disj-sym}
% \end{lemma}

\begin{figure}[t]
  \begin{small}
    \centering
    \drules[bl]{$[[botlike A]]$}{Bottom-Like Types}{bot, or}
  \end{small}
  \begin{small}
    \centering
    \drules[ad]{$[[A * B]]$}{Algorithmic Disjointness}{btmr, btml, intl, intr, orl, orr}
  \end{small}
  \begin{small}
    \centering
    \drules[typ]{$ [[G |- e dirflag A]] $}{Bi-directional Typing}{int, var, ann, app, sub, abs, switch}
  \end{small}
  \caption{Bottom-Like types, Algorithmic Disjointness and Typing for \cal.}
  \label{fig:union:disj-typ}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%
%% Typing
%%%%%%%%%%%%%%%%%%%%%
\subsection{Typing}
\label{sec:union:typ}
The typing rules are shown at the bottom of \Cref{fig:union:disj-typ}.
We adopt bi-directional type-checking~\cite{} in our calculus.  There
are two typing modes in bi-directional typing: inference mode
($[[=>]]$) and checking mode ($[[<=]]$). In the inference mode, the type of
an expression $[[e]]$ is inferred.  In the checking
mode, an expression $[[e]]$ is checked against a given type $[[A]]$.
Typing rules are mostly standard. An integer
expression $[[i]]$ infers type $[[Int]]$ as stated in \rref{typ-int}.
\Rref{typ-var} states that a variable $[[x]]$ infers type $[[A]]$ if
$[[x]]$ has type $[[A]]$ in the given context. \Rref{typ-ann}
checks an expression $[[e]]$ against the given type annotation $[[A]]$,
and infers type $[[A]]$.

\Rref{typ-app} is the standard bi-directional rule for
function application. In \rref{typ-app}, note that the type of the
function $[[e1]]$ is inferred. Thus the expression $[[e1]]$ should carry
its own type information, and it will typically include annotated lambdas.
On the other hand, the argument expression $[[e2]]$ is checked against type $A$,
and can itself be a function. For instance we could have $[[e2]] = \lambda x. x$
and $[[A]] = [[Int->Int]]$. In such case, during reduction, the argument would be
the unnanotated value $\lambda x. x$.
\Rref{typ-sub} is the subsumption rule. It states that an expression
$[[e]]$ can be checked against any supertype of its inferred type.
\Rref{typ-abs} is the standard introduction rule for lambda
expressions. To check a lambda expression $[[\x.e]]$ against type $[[A
    -> B]]$, it is sufficient to check lambda body $[[e]]$ against the
output type $[[B]]$ in an extended context with parameter $[[x]]$ of
input type $[[A]]$.

The most interesting and novel typing rule is for
\emph{switch} expressions. There are four conditions.
%The remaining conditions are standard for a calculus with
%union types and case expression and have been studied in various
%calculi (\baber{reference to calculi}).
The first condition ($[[G |-
    e <= A \/ B]]$) ensures that case expression $[[e]]$ is well-typed
and checks against type $[[A \/ B]]$. Note that this condition ensures
\emph{exhaustiveness} of the cases in the switch: $e$ must
check against the types in the branches of the switch. 
The next two conditions ensure that
branches of case expressions are well-typed and check against type
$[[C]]$, which is the overall type of the switch expression.
An important point in these two conditions is that variables
$[[x]]$ and $[[y]]$ are, respectively, of type $[[A]]$ in first branch and of type $[[B]]$ in
second branch in the extended context. 
%\snow{So they are exhaustive for all possible values of $e$. In other words,
%at least one branch matches with the runtime type of $e$.}
The last condition
$[[A *s B]]$, guarantees \emph{disjointness} of $[[A]]$ and $[[B]]$.
This ensures that overlapping types for the branches of case expressions
are forbidden. Otherwise, overlapping types could lead to
non-deterministic results.
Since all the branches check against $[[C]]$, the whole
switch expression checks against $[[C]]$.
\snow{Note that the two branches can have different return types.
For example, they infer to $A'$ and $B'$ respectively. In that case, the whole
expression can be checked by $[[A' \/ B']]$.}\bruno{I think Snow's point may be something
for the discussion section, perhaps.}

\begin{comment}
\begin{figure}[t]
  \begin{small}
    \centering
    \drules[typ]{$ [[G |- e dirflag A]] $}{Bi-directional Typing}{int, var, ann, app, sub, abs, typeof}
  \end{small}
  \caption{Typing for \cal.}
  \label{fig:union:typ}
\end{figure}
\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%
%% Operations Semantics
%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Operational Semantics}
\label{sec:union:os}
The dynamics of \cal is defined by a small-step operational semantics. An
important aspect of the semantics is that it is type-directed
\cite{Huang:typedirected}, where type annotations are used to guide reduction,
and similar terms that differ only on type annotations can reduce in different
ways.

\paragraph{The role of type annotations}
Type annotations play two important roles in the calculus.
Firstly, static types are used by the switch construct
to select the correct branch to execute. Secondly, the
dynamic types are needed to ensure type preservation.
\bruno{The text that was here before (commented now)
  was just repeating stuff that we already said before.
  What we need here is text that explains how and where annotations are used during reduction.
  For instance switches need the static types to select the branches correctly. Furthemore
the static types are necessary for preservation. So illustrate those two points with examples. }
\begin{comment}
Before going
into the details of operational semantics, it is important to recall
the definition of pre-values, annotated values and values.
An integer expression $[[i]]$ is not a value unless annotated.
Non-annotated lambda expressions ($[[\x.e]]$) are values but cannot appear at left
side in function applications.
Only annotated values $[[w]]$ can appear at left side in function applications.
Annotated values consist of annotated pre-values. That is, it consists of
$[[i:A]]$ and $[[\x.e:(A1->B1):(A2->B2)]]$. This is
because that the orginal static type is tracked by the operational semantics.
Therefore, we can end up in a value such as $[[1 : Int]]$ or $[[1 : Top]]$,
and those two values can behave differently in some contexts.
\bruno{Give an example here}
For functions the static type is not enough and we also need the dynamic type
(which is the original type of the lambda).
For example, if we have:
$e = [[\x.x:Int->Int:(Int->Int)\/(Bool->Bool)]]$, then the static type of $e$ is
$[[(Int->Int)\/(Bool->Bool)]]$ and the, more precise, dynamic type is
$[[Int->Int]]$.
\end{comment}
If we use the following switch expression:

\bruno{example here with a switch}

The static type is used to select the correct branch of the switch statement.
The presence of annotations with the dynamic types, on the other hand,
ensures that types are preserved during substitution in
beta-reduction and \emph{switch} cases.\bruno{another example for illustrating
preservation.}

\paragraph{Reduction rules}
\Cref{fig:union:os} shows operational semantics of \cal.
The operational semantics follows a call-by-value evaluation strategy.
\Rref{step-int} annotates integer expressions and makes them
values. \Rref{step-appl} is a standard call-by-value rule, reducing
the left expression of an application.
\Rref{step-appr} is almost a standard call-by-value rule, except
that we know that the left expression in the application must reduce
to an annotated value ($[[w]]$): non-annotated lambda expressions
($[[\x.e]]$) cannot appear at left side in applications.
\ningning{\rref{step-appr} looks very fishy. Why $[[w]]$ on the left becomes
  $[[v]]$ on the right?}
%Therefore, we have a condition of annotated value ($[[w]]$) at left
%side of applications instead of value $[[v]]$.
%\Rref{step-appr} then reduces right expression of application
%to a value.

\bruno{Following text needs to be fixed after changes in Figure.}
\Rref{step-beta} is the beta-reduction rule. It applies a dually
annotated lambda value $[[\x.e : A1 -> B1 : A2 -> B2]]$ to input
value $[[v]]$. Substitution replaces free occurences of variable
$[[x]]$ with $[[e1:A2:A1]]$.
Drop Static Type ($\rceil[[v]]\lceil$) drops the static type
from annotated values $[[p:A]]$ and returns $[[p]]$.
It does not change non-annotated values $[[\x.e]]$ and returns 
them as it is. The result expression $[[e1]]$ of ($\rceil[[v]]\lceil$)
is either a pre-value $[[p]]$ or $[[\x.e]]$.
Therefore, there are two cases to be considered in beta-reduction
during substitution: one for pre-values and the other for $[[\x.e]]$.

For the first case, note that the annotation of the pre-value
$[[p]]$ changes from $[[p:A]]$ to $[[p:A2:A1]]$ during substitution.
Specifically,
$\rceil[[v]]\lceil$ drops $[[A]]$ from $[[p:A]]$ and returns $[[p]]$ 
as $[[e1]]$. Substitution then
substitutes free occurrences of variable $[[x]]$ with $[[e1:A2:A1]]$.
\snow{Question about the rule design: why drop $A$? Substituting $x$ by
$[[p:A:A2:A1]]$ should have the same effect as $[[p:A2:A1]]$.
On the other hand, why adding $[[A2]]$ after dropping $[[A]]$
instead of using $[[p:A1]]$?}
This is to keep the most specific type in the annotation. A substituted
expression is also annotated with both of the output types from
annotated lambda expression.
\snow{For the above sentence: We need double annotation here because the
result of function application might be a raw lambda, right?}
The second case occurs when the
argument of a function is a non-annotated lambda expression.
With bi-directional type-checking an expression such as:
$([[\f.f 1: (Int -> Int -> Int) : (Int -> Int -> Int)]]) ([[\x.x]])$
\snow{The type annotation is incorrect. Arrows are right-associative.}
\bruno{example here.} \baber{Done.}
is well-typed, since bi-directional type-checking propagates
type information to the arguments. Thus, the dynamic semantics
needs to deal with such programs. Substitution for second case goes
as for first case, except that $\rceil[[v]]\lceil$ returns $[[\x.e]]$ as it is.

\Rref{step-ann}
reduces an annotated expression only if it is not an annotated value and $[[e]]$
reduces to some $[[e']]$. \Rref{step-rmann} drops inner
annotations. \Rref{step-lamann} adds one more type annotation to
lambda expressions with only single type annotation to make them values.

\begin{comment}
\Rref{step-beta} deals with a special case, that occurs when the
argument of a function is a non-annotatted lambda expression.
With bi-directional type-checking an expression such as:
($[[\f.f 1:(Int -> Int -> Int) : (Int -> Int -> Int)]]$)($[[\x.x]]$)
\bruno{example here.} \baber{Done.}
is well-typed, since bi-directional type-checking propagates
type information to the arguments. Thus, the dynamic semantics
needs to deal with such programs.
We emphasize the fact that $[[\x.e]]$ is not a value in \cal.
The rule follows the same approach as
\rref{step-beta} except that both of the input types are kept with
$[[\x.e]]$ during substitution i.e $[[\x.e:A2:A1]]$. \Rref{step-ann}
reduces an annotated expression only if it is not a value and $[[e]]$
reduces to some $[[e']]$. \Rref{step-rmann} drops inner
annotations. \Rref{step-lamann} adds one more type annotation with
lambda expressions having single type annotation to make them values.
\end{comment}

Of particular interesting are
\rref{step-switch, step-switchl, step-switchr}, which deal with the reduction
of \emph{switch} expressions.
\snow{I have the same linking problem for switchl/r rules here as well.
Clicking them just bring me to the beginning of the pdf.}
\Rref{step-switch} reduces the case expression $[[e]]$ unless it
becomes a value of the form $[[p:D]]$.  
\snow{I suggest explain why the value cannot have a form of lambda here.}
\Rref{step-switchl} evaluates
the left branch of the \emph{switch} expression if the dynamic type of $[[p]]$ is
a subtype of type of left branch, while \rref{step-switchr} evaluates the right
branch if type of $[[e]]$ is subtype
of type of the right branch. The subtyping condition in \rref{step-switchl,
  step-switchr} is important, as it gives
freedom of various subtypes of $[[A]]$ and $[[B]]$ for a corresponding
branch instead of only type $[[A]]$ and type $[[B]]$. Recall that
the typing rule for \emph{switch} (\rref{typ-switch}) requires that
types of left and right branches of a \emph{switch}
expression to be disjoint.
This ensures \rref{step-switchl,step-switchr} cannot overlap, which, as we will
see, is important for the
operational semantics to be \textit{deterministic}.
\bruno{The following sentence is out-of-place. It should appear earlier
  when we talk about disjointness. Perhaps you can state the property
formally at that point.}
A natural property of \cal is
if type $[[A]]$ and type $[[B]]$ are two disjoint types, then subtypes
of $[[A]]$ are also disjoint to subtypes of $[[B]]$.

\paragraph{Dynamic Type} \baber{text for dropstatictype.} The dynamic semantics employs a simple
function that retrieves the dynamic type of a partial value. \snow{A pre-value?}
The definition
is shown in the lower part of \Cref{fig:union:os}.
$[[Int]]$ is returned when $[[p]]$ is an integer $[[i]]$ (\rref{findtype-int}).
Otherwise, for functions, the function annotation $[[A -> B]]$ is returned
(\rref{findtype-arrow}).

\begin{figure}[t]
  \begin{small}
    \centering
    \drules[step]{$[[e --> e']]$}{Operational Semantics}{int, appl, appr, beta, ann, rmann, lamann, switch, switchl, switchr}
  \end{small}
%  \begin{small}
%    \centering
%    \drules[findtype]{$[[findtype p A]]$}{FindType}{int, arrow}
%  \end{small}
  \bigskip
  %\begin{small}
  \begin{center}
  {\renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|llcl|}
      \hline
      Beta Value $\rceil$$[[v]]$$\lceil$ &  & & \\
     & $\rceil$$[[p:A]]$$\lceil$ & = & $[[p]]$ \\
     & $\rceil$$[[\x.e]]$$\lceil$ & = & $[[\x.e]]$ \\
      \hline
    \end{tabular} } \\
  \bigskip
  %\begin{small}
  {\renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|llcl|}
      \hline
      Static Type $\rfloor$$[[p]]$$\lfloor$ &  & & \\
     & $\rfloor$$[[i]]$$\lfloor$ & = & $[[Int]]$ \\
     & $\rfloor$$[[\x.e: A -> B]]$$\lfloor$ & = & $[[A -> B]]$ \\
      \hline
    \end{tabular} }
    \end{center}
  \caption{Operational semantics, DropStaticType and DynamicType relation for \cal.}
  \label{fig:union:os}
\end{figure}
\bruno{Don't introduce $[[e1]]$ and $C$ in rules step-beta, step-switchl and step-switchr.
  Change the notations, since we already use similar notation for bottom-like types. Also, change
the step-beta rule as discussed in slack, both in the paper and in Coq.} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Type Safety and Determinism
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Type Safety and Determinism}
\label{sec:union:safety}
\cal is type sound and deterministic. In this section we discuss the
proofs of type safety and determinism for \cal. Type soundness is established
by the type preservation and progress
theorem. Type preservation (\Cref{lemma:union:preservation}) states that
types are preserved during reduction. Progress
(\Cref{lemma:union:progress}) states that well typed programs never get
stuck.  A well typed expression $[[e]]$ is either a value or it can
take step to some other expression $[[e']]$. Therefore, preservation and progress
together ensure type safety.
%We add one more choice in the conclusion
%of progress lemma to handle non-annotated lambda expressions
%($[[\x.e]]$). This last condition is necessary because the type system
%employs bi-directional type checking and unannotated lambdas (which are not values)
%can be well-typed in the checking mode.

\begin{theorem}[Type Preservation]
\label{lemma:union:preservation}
  If \ $[[G |- e dirflag A]]$ and $[[e --> e']]$ then $[[G |- e' dirflag A]]$.
\end{theorem}

\begin{comment}
\begin{proof}
  By induction on typing relation and subsequent inverting reduction relation.
  \begin{itemize}
    \item Cases \rref{typ-int, typ-var, typ-sub, typ-abs} are trivial to prove.
    \item Case \rref{typ-ann} requires helping \cref{lemma:union:check-pexpr-ann}.
    \item Case \rref{typ-app} requires helping \cref{lemma:union:pexpr-check-sub}
          and substitution \cref{lemma:union:substitution} for beta reduction.
    \item Case \rref{typ-typeof} requires substitution \cref{lemma:union:substitution}.
  \end{itemize}
\end{proof}

\baber{ToDo: change name of helping lemmas.}

\begin{lemma}[check-pexpr-ann]
\label{lemma:union:check-pexpr-ann}
  If \ $[[G |- p:C <= A]]$ \ then \ $[[G |- p <= A]]$.
\end{lemma}

\begin{lemma}[pexpr-check-sub]
\label{lemma:union:pexpr-check-sub}
  If \ $[[G |- p <= A]]$ \ and \ $[[A <: B]]$ \ then \ $[[G |- p <= B]]$.
\end{lemma}
\end{comment}

\begin{lemma}[Progress]
\label{lemma:union:progress}
If \ $[[ [] |- e dirflag A]]$ then
 \begin{enumerate}
  \item either $[[e]]$ is a value.
  \item or $[[e]]$ can take a step to $[[e']]$.
  \end{enumerate}
\end{lemma}

\ningning{I removed Substitution lemma because it's uninteresting.}

\begin{comment}
\begin{lemma}[Substitution]
  \label{lemma:union:substitution}
  If \ $[[G, x:B , G1 |- e dirflag A]]$ \ and \ $[[G |- e' => B]]$
  then \ $[[G, G1 |- e [ x ~> e' ] dirflag A]]$
\end{lemma}

\begin{proof}
By induction on typing relation.
  \begin{itemize}
    \item Cases \rref{typ-int, typ-var, typ-app, typ-sub, typ-abs} are trivial to prove.
    \item Case \rref{typ-anno} requires \cref{lemma:union:value-not-value}.
    \item Case \rref{typ-typeof} requires
    \cref{lemma:union:check-pexpr-ann,lemma:union:check-or-typ,lemma:union:pexpr-inf-typ}.
  \end{itemize}
\end{proof}

\begin{lemma}[Value Decidability]
\label{lemma:union:value-not-value}
$\forall$ $[[e]]$, \ value \ $[[e]]$ \ $\vee$ \ $\neg$ value \ $[[e]]$.
\end{lemma}

\begin{lemma}[check-or-typ]
\label{lemma:union:check-or-typ}
If \ $[[A *s B]]$ \ and \ $[[G |- p <= A \/ B]]$ \ then:
  \begin{enumerate}
    \item either \ $[[G |- p <= A]]$
    \item or \ $[[G |- p <= B]]$
  \end{enumerate}
\end{lemma}

\begin{lemma}[pexpr-inf-typ]
\label{lemma:union:pexpr-inf-typ}
If \ $[[G |- p <= A]]$ \ then:
  \begin{enumerate}
  \item $\exists$ $[[B]]$, \ $[[B <: A]]$
  \item and \ $[[G |- p => B]]$
  \end{enumerate}
\end{lemma}
\end{comment}

We further show that the operational semantics is deterministic, which ensures
that a program will always produce the same unique result. This property is not
obvious as many operational semantics rules distinguish between pre-values,
values and annotated values. Also, by proving determinism, we guarantee that
switch expressions are not order-sensitive: at any time, only one of the
\rref{Step-Switchl,Step-Switchr} can be applied to a well-typed expression.

\begin{theorem}[Determinism]
\label{lemma:union:determinism}
  If \ $[[G |- e dirflag A]]$ and \ $[[e --> e1]]$ and \ $[[e --> e2]]$ then $[[e1]]$ = $[[e2]]$.
\end{theorem}

\begin{comment}
\begin{proof}
  By induction on first reduction relation and inverting second reduction relation subsequently.
  All cases are trivial to solve by simple inversions except:
  \begin{itemize}
    \item Case \rref{typ-typeof} requires \cref{lemma:union:check-both-disj-false}.
  \end{itemize}
\end{proof}

\begin{lemma}[check-both-disj-false]
\label{lemma:union:check-both-disj-false}
If \ $[[A *s B]]$ \ and \ $[[G |- p <= A]]$ \ and \ $[[G |- p <= B]]$ \ then \ False.
\end{lemma}
\end{comment}

\baber{Again, should we show the property that a term cannot be checked against two disjoint types?}
\bruno{I think you can and connect that to the last point in the text above, perhaps.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Discussion on Disjointness
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{An Alternative Specification for Disjointness}
\label{sec:union:discussion}
\begin{comment}
\snow{I feel the reason and consequence are flipped here. 
The alternative spec definitely equals to the previous one
because we define ``ordinary types" to satisfy:
1) no bottom-like types are ordinary;
2) any type must have an ordinary subtype if it is not bottom-like.
Or we need to provide some intuition for ordinary types themselves.}
\end{comment}

The current definition of disjointness (\Cref{def:union:disj}) is inspired
by work on disjoint intersection types~\cite{oliveira2016disjoint}. This definition works well
for the calculus presented in this section. However it is not the only
possible formulation of disjointness.
An equivalent formulation of disjointness is:

\begin{definition}
    A $*_{s1}$ B $\Coloneqq$ $\forall$ C, $[[ordinary C]]$ $\rightarrow$ $\neg$ ($[[C <: A]]$ $\wedge$ $[[C <: B]]$)
    \label{def:union:disj1}
  \end{definition}

\noindent
The new disjointness definition (\Cref{def:union:disj1}) states that two
types are disjoint if they do not have common ordinary subtypes.
\emph{Ordinary types}, are essentially
those types that are primitive, such as integers and functions:

\drules[ord]{$[[ordinary A]]$}{Ordinary Types}{int, arrow}
\medskip

\noindent Note that the static types of (pre-)values in \name are always ordinary.
%Consequentely values with a dynamic type $A$ should have an ordinary subtype $B$,
%such that $B <: A$. 
%terms with bottom types cannot be reduced to values
%It is important to establish the fact that definition
%\Cref{def:union:disj1} is indeed equivalent to our current
%definition. 
We prove equivalence of \Cref{def:union:disj} and
\Cref{def:union:disj1}:

\begin{lemma}[Disjointness Equivalence]
A $*_{s}$ B $\longleftrightarrow$ A $*_{s1}$ B.
\end{lemma}

The reason to introduce \Cref{def:union:disj1} is that this definition
will play an important role in the calculus presented in Section~\ref{sec:inter},
since \Cref{def:union:disj} cannot be used in that setting.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% org-ref-default-bibliography: "../paper.bib"
%%% End: