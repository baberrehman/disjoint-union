\section{The Union Calculus (\name)}
\label{sec:union}

This section introduces the union calculus \name. The distinctive feature
of the \name calculus is a type-based switch expression with disjoint
cases, which can be used to eliminate values with union types.
%Such type-based
%switch expression is inspired by a similar construct in the Ceylon programming
%language.
We adapt the notion of disjointness from previous work on
\emph{disjoint intersection types}~\cite{oliveira2016disjoint} to \name, and show that \name is type
sound and deterministic.

%%%%%%%%%%%%%%%%%%%%%
%% Syntax
%%%%%%%%%%%%%%%%%%%%%

\subsection{Syntax}\label{sec:union:syntax}
\Cref{fig:union:syntax} shows the syntax for \cal. Metavariables
$[[A]]$, $[[B]]$ and $[[C]]$ range over types.  Types include top ($[[Top]]$),
bottom ($[[Bot]]$), function ($[[A -> B]]$) and union ($[[A \/ B]]$)
types. Metavariable $[[e]]$ ranges over program
expressions. Expressions include variables ($[[x]]$), natural numbers
($[[i]]$), type annotations ($[[e:A]]$), lambda abstractions
($[[\x.e]]$), applications ($[[e1 e2]]$) and a novel switch ($[[switch
    e A e1 B e2]]$) expression. \emph{Switch} expression is a case
expression and evaluates a specific branch by matching the
type.
%Details of \typeof expression will further be discussed in typing
%and operational semantics sections.
\snow{I think $i$ stands for integers not only natural numbers.
And we need to say switch must have two exhaustive branches (perhaps
later in the typing part).}

\paragraph{Values, pre-values and annotated values} In \name all the values have
a type annotation except of non-annotated lambda expression ($[[\x.e]]$).
The type annotation represents the dynamic type
that the value has at runtime, and
it is helpful for the type-directed dynamic semantics.
\snow{For lambdas, the inner annotation stands for its dynamic type, right?
Reading the above sentence makes me feel the outside annotation stands for
the dynamic type.}
We divide the representation for values into three parts: pre-values,
annotated values and values.
Metavariable $[[p]]$ ranges over pre-values. Pre-values
consist of natural numbers $[[i]]$
and annotated lambda expressions $[[\x.e : A -> B]]$.
Metavariable $[[w]]$ ranges over annotated values. 
Annotated values are pre-values with an additional type annotation i.e. $[[p:A]]$.
Metavariable $[[v]]$ ranges over
values. It consists of annotated values $[[w]]$ and non-annotated 
lambda expressions $[[\x.e]]$.
It is important to note that $[[i]]$ is not a value in this
calculus, instead $[[i:Int]]$ or $[[i:Top]]$ are values.
Values which are non-annotated lambda expressions ($[[\x.e]]$) are special case
and cannot appear at left side in function applications.
\snow{I feel the above sentence can be rephrased in a simpler way.
And, can we say that after the typing rule for application is revealed?}
In addition, lambdas have two annotations in annotated values $[[w]]$.
That is $[[\x.e : A -> B : C]]$ is a value and can appear at left side in function application.
\snow{Same applies to this statement about function application.}
As already mentioned, $C$ is the dynamic type of the value
at runtime, whereas $[[A -> B]]$ is the original \emph{static type} of the lambda.
For readers familiar with calculi with gradual types~\cite{}, the two annotations
can be also be understood as the \emph{source type} and \emph{target type}
of an upcast: i.e. if the value is well-typed we have that $[[A -> B]] <: [[C]]$.
\snow{Is it really related to gradual typing? Or just type casting?}

A context ($[[G]]$) can
either be empty or contains type bindings of variables and associated
types. Finally, a typing mode ($[[dirflag]]$) can either be check ($[[<=]]$)
or inference ($[[=>]]$).

\begin{figure}[t]
  \begin{small}
    \centering
    \begin{tabular}{lrcl} \toprule
      Types & $[[A]], [[B]]$, $[[C]]$ & $\Coloneqq$ & $ [[Top]] \mid [[Bot]] \mid [[Int]] \mid [[A -> B]] \mid [[A \/ B]] $ \\
      Expr & $[[e]]$ & $\Coloneqq$ & $[[x]] \mid [[i]] \mid [[e:A]] \mid [[\x.e]] \mid [[e1 e2]] \mid [[switch e A e1 B e2]]$\\
      PValue & $[[p]]$ & $\Coloneqq$ & $[[i]] \mid [[\x.e : A -> B]] $\\
      AValue & $[[w]]$ & $\Coloneqq$ & $[[p:A]]$\\
      Value & $[[v]]$ & $\Coloneqq$ & $[[w]] \mid [[\x.e]] $\\
      Context & $[[G]]$ & $\Coloneqq$ & $ \cdot \mid [[G , x : A]]$ \\
      Mode & $[[dirflag]]$ & $\Coloneqq$ & $[[<=]] \ \mid \ [[=>]]$ \\
      \bottomrule
    \end{tabular}
  \end{small}
  \begin{small}
    \centering
    \drules[s]{$ [[A <: B ]] $}{Algorithmic Subtyping}{top, bot, int, arrow, ora, orb, orc}
  \end{small}
  \ningning{Why we say the subtyping definition is algorithmic but it is not
    even syntax-directed?}

  \caption{Syntax and Algorithmic Subtyping for \cal. \snow{We need to add C as
      a metavariable for types here because it is used later.} \baber{Done.} }
  \label{fig:union:syntax}
\end{figure}
\bruno{Add the syntax for the bi-directional modes in the Figure.} \baber{Done.}

%%%%%%%%%%%%%%%%%%%%%
%% Subtyping
%%%%%%%%%%%%%%%%%%%%%
\subsection{Subtyping}
\label{sec:union:sub}
Algorithmic subtyping rules for \cal are shown in
\Cref{fig:union:syntax}. The subtyping rules are standard for a system
with union types.  
\snow{This above sentence is repetitive to the later statement about
the three union rules.}
\Rref{s-top} states that all types are subtypes of
the $[[Top]]$ type. \Rref{s-bot} states that $[[Bot]]$ type is subtype of
all types. \Rref{s-int, s-arrow} are standard rules for integers and
functions respectively.  Functions are contravariant in input types
and covariant in output types. \Rref{s-ora, s-orb, s-orc} are standard
subtyping rules for union types. The union type of two types $A1$ and $A2$
is a subtype of another type $A$ if both $A1$ and $A2$ are subtypes of
$A$, as stated in \rref{s-ora}. \Rref{s-orb, s-orc} states that if a
type is subtype of one of the components of a union type, then it is subtype of whole
union type.  
\snow{The link for s-orc is lost. Maybe we need to use ``and \rref{s-orc}" instead? Can we use $B$ instead of $A$ in the three union rules to make them
more readable? Btw ``states" should be ``state".}
The subtyping relation for \cal is reflexive and transitive.
\begin{lemma}[Subtyping Reflexivity]
  $[[A <: A]]$.
\label{lemma:union:refl}
\end{lemma}
\begin{comment}
\begin{proof}
  By induction on type A. All cases are trivial to prove.
\end{proof}
\end{comment}
\begin{lemma}[Subtyping Transitivity]
  If \ $[[A <: B]]$ \ and \ $[[B <: C]]$ \ then \ $[[A <: C]]$.
  \label{lemma:union:trans}
\end{lemma}
\begin{comment}
\begin{proof}
  By induction on type B.
  \begin{itemize}
    \item Cases $[[Top]]$, $[[Bot]]$ and $[[Int]]$ are trivial to prove.
    \item Case $[[A -> B]]$ requires double induction on type $[[C]]$
          and $[[A]]$.
    \item Case $[[A \/ B]]$ requires \Cref{lemma:union:sub-or}
  \end{itemize}
\end{proof}\bruno{If space is a concern we can probably drop the lemma statements
for reflexivity and transitivity as these are quite standard.}

\begin{lemma}[Subtyping Union Inversion]
\label{lemma:union:sub-or}
  If \ $[[A \/ B <: C]]$ then:
  \begin{enumerate}
    \item $[[A <: C]]$ and
    \item $[[B <: C]]$
  \end{enumerate}
\end{lemma}
\end{comment}


%%%%%%%%%%%%%%%%%%%%%%%
%% Disjointness
%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Disjointness}
\label{sec:union:disj}
\baber{Mainly focused on technical details in this section. Story and benefits of disjointness may be discussed in another section.}
In this section we discuss in detail the notion of disjointness for
union types and case expression for \cal. In essence disjointness for \cal is
the dual to disjointness for $\lambda_i$~\cite{oliveira2016disjoint}, which is
a calculus with disjoint intersection types. In $\lambda_i$, two
types in are disjoint if they do not share any common
\emph{supertype} which is not \emph{top-like}. In contrast, in
\cal, two types in are disjoint if they do not share any common \emph{subtype} which
is not \emph{bottom-like}.
\bruno{In the overview section we need to talk about more about this and
explain that common subtypes are important for the switch expression.}
We emphasize the significance of
\emph{supertypes} and \emph{subtypes} in $\lambda_i$ and \cal
respectively.

\paragraph{Bottom-Like Types}
\emph{Bottom-like} types are types that are isomorphic (i.e.
both supertypes and subtypes) of the type $\bot$. In \name there
are infinitely many such types, including, for example $\bot \lor \bot$,
$\bot \lor \bot \lor \bot$, as well as $\bot$ itself. Bottom-like types
are important because they allow us to define disjointness.
%are integral part of disjoitness in \cal like
%\emph{top-like} in $\lambda_i$ \cite{oliveira2016disjoint}. Therefore,
%it is important to understand the notion of \emph{bottom-like} types
%before diving into the details of disjointness.
Intuitively, a
\emph{bottom-like} type is a type which behaves like $[[Bot]]$ type.
An inductive definition that captures all the bottom-like types
is shown at the top of \Cref{fig:union:disj-typ}.
Type $[[Bot]]$ is obviously a \emph{bottom-like} type
(\rref{bl-bot}), and a union type of two \emph{bottom-like} types is also
a \emph{bottom-like} type (\rref{bl-or}).  It is trivial to conclude
that a union type is \emph{bottom-like} only if all the primitive
types in union are $[[Bot]]$. The correctness of our definition for
bottom-like types is ensured by the following properties:
\snow{Why we need an extra definition for bottom-like rather than
directly using ``A<:Bot"? And the notation overlaps with the
DynamicType function later.}

\begin{lemma}[Bottom-Like Soundness]
  If \ $[[botlike A]]$ \ then \ $[[A <: B]]$.
\label{lemma:union:bl-soundness}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on bottom-like relation.
  \begin{itemize}
    \item All cases are trivial to prove.
  \end{itemize}
\end{proof}
\end{comment}

\begin{lemma}[Bottom-Like Completeness]
  If \ $[[A <: B]]$ \ then \ $[[botlike A]]$.
\label{lemma:union:bl-completeness}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on type $[[A]]$.
  \begin{itemize}
    \item Cases $[[Top]]$, $[[Bot]]$, $[[Int]]$ and $[[A -> B]]$ are trivial to prove.
    \item Case $[[A \/ B]]$ requires \Cref{lemma:union:sub-or}.
  \end{itemize}
\end{proof}
\end{comment}

\paragraph{Declarative Disjointness}
The formal (declarative) definition for disjointness in \name is:
%Recall that two types in \cal are disjoint if they do not share any common subtype which is not
%\emph{bottom-like}. The formal definition of disjoint specifications for this calculus is:

\begin{definition}
  A $*_s$ B $\Coloneqq$ $\forall$ C, $[[C <: A]]$ $\wedge$ $[[C <: B]]$ $\rightarrow$ $[[botlike C]]$
\label{def:union:disj}
\end{definition}

\noindent That is, two types are disjoint if all their common subtypes are bottom-like.
\begin{comment}
With this definition we have that different primitive types are disjoint. For example
$[[Int]] * [[Bool]]$ since the only common subtypes of $[[Int]]$ and $[[Bool]]$
are bottom-like. A more interesting case is the disjointness of two function types.
It turns out that function types are never disjoint, since we can always find
a common subtype for any two function types. For example, if we have $[[Int -> Bool]]$
and $[[String -> Char]]$ then a common subtype that is not bottom-like is
$[[Top -> Bot]]$. Therefore, $[[Int -> Bool]]$ and $[[String -> Char]]$ are not
disjoint.

\noindent Reader may think at this point that $[[Bot]]$ type can simply be used in \Cref{def:union:disj}
instead of $[[botlike C]]$ in the conclusion. Answer to this question is
union type with $[[Bot]]$ as all primitive types is also a least subtype in \cal.
$[[botlike C]]$ also handles this case.
\end{comment}
We illustrate this definition with a few simple examples:

\begin{enumerate}
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Int -> Bool]]:}$ \\
        $[[Int]]$ and $[[Int -> Bool]]$ are disjoint types. All common subtypes of $[[Int]]$ and $[[A -> B]]$ are bottom-like types,
        including $[[Bot]]$ and union of $[[Bot]]$ types.
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Bot]]:}$ \\
    $[[Int]]$ and $[[Bot]]$ are disjoint types, since again all common subtypes are bottom-like. In general, the type $[[Bot]]$ (or any other bottom-like type)
    is disjoint to any other type.
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Int]]:}$ \\
        $[[Int]]$ and $[[Int]]$ are not disjoint types because they share a common subtype $[[Int]]$ which
        is not \emph{bottom-like}.
  \item $\boldsymbol{A = [[Int]], \ B = \ [[Top]]:}$ \\
        $[[Int]]$ and $[[Top]]$ are not disjoint types because they share a common
    subtype $[[Int]]$ which is not \emph{bottom-like}. In general no type
    is disjoint to $[[Top]]$. \snow{Except for bottom-like types.}
  \item $\boldsymbol{A = [[Int -> Bool]], \ B = \ [[String -> Char]]:}$
    The types $[[Int -> Bool]]$ and $[[String -> Char]]$ are not disjoint,
    since they share we can find non-bottom-like types that are subtypes
    of both types. For instance $[[Top -> Bot]]$ is a subtype of both types.
    More generally, any two function types can never be disjoint: it is always
    possible to find a common subtype, which is not bottom-like.
    \\
\end{enumerate}
\snow{I like the idea to use examples here. Can we have one or two with union types
involved as well?}

\begin{comment}
\begin{figure}[t]
  \begin{small}
    \centering
    \drules[ad]{$[[A * B]]$}{Algorithmic Disjointness}{btmr, btml, intl, intr, orl, orr}
  \end{small}
  \caption{Algorithmic Disjointness for \cal.}
  \label{fig:union:ad}
\end{figure}
\end{comment}

\paragraph{Algorithmic Disjointness}
The middle part of \Cref{fig:union:disj-typ} shows an algorithmic
version of disjointness.  \Rref{ad-btmr, ad-btml} state that the $[[Bot]]$
type is disjoint to all types.  \Rref{ad-intl, intr} state that
$[[Int]]$ and $[[A -> B]]$ are disjoint types.  Algorithmic
disjointness can further be scaled to more primitive disjoint types
such as $Bool$ and $String$ by adding more rules similar to
\rref{ad-intl, intr} for additional primitive types.  \Rref{ad-orl,
  ad-orr} are two symmetric rules for union types. Any type $[[C]]$ is
disjoint to an union type $[[A \/ B]]$ if $[[C]]$ is disjoint to both
$[[A]]$ and $[[B]]$.  Algorithmic disjointness is sound and complete
with respect to \Cref{def:union:disj}, and disjointness is a symmetric
relation. The following lemmas summarize key properties of disjointness.

\begin{lemma}[Disjointness Soundness]
  If \ $[[A * B]]$ \ then \ $[[A *s B]]$.
\label{lemma:union:disj-sound}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on algorithmic disjointness relation.
  \begin{itemize}
    \item Cases \rref{ad-btmr, ad-btml, ad-orl, ad-orr} require induction on hypothesis
          and \Cref{lemma:union:sub-or}.
    \item Cases \rref{ad-intl, ad-intr} require induction on type and \Cref{lemma:union:sub-or}.
  \end{itemize}
\end{proof}
\end{comment}

\begin{lemma}[Disjointness Completeness]
  If \ $[[A *s B]]$ \ then \ $[[A * B]]$.
\label{lemma:union:disj-complete}
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on type A.
  \begin{itemize}
    \item Case $[[Top]]$ requires \Cref{lemma:union:bl-disj}.
    \item Case $[[Bot]]$ is trivial to prove.
    \item Case $[[Int]]$ requires induction on type B and
          \Cref{lemma:union:bl-disj,lemma:union:disj-sym}.
    \item Case $[[A -> B]]$ requires induction on type B and \Cref{lemma:union:disj-sym}.
    \item Case $[[A \/ B]]$ follows directly from inductive hypothesis.
  \end{itemize}
\end{proof}

\begin{lemma}[Bottom-like Types Disjoint]
\label{lemma:union:bl-disj}
  If \ $[[botlike A]]$ \ then: \ $[[A * B]]$.
\end{lemma}

\begin{lemma}[Disjointness Symmetry]
\label{lemma:union:disj-sym}
  If \ $[[A * B]]$ \ then: \ $[[B * A]]$.
\end{lemma}
\end{comment}

\begin{lemma}[Bottom-Like Disjoint]
  If \ $[[botlike A]]$ \ then \ $[[A * B]]$.
\label{lemma:union:bl-disjoint}
\end{lemma}

\begin{lemma}[Disjointness Symmetry]
  If \ $[[A * B]]$ \ then \ $[[B * A]]$.
\label{lemma:union:disj-sym}
\end{lemma}

\begin{figure}[t]
  \begin{small}
    \centering
    \drules[bl]{$[[botlike A]]$}{Bottom-Like Types}{bot, or}
  \end{small}
  \begin{small}
    \centering
    \drules[ad]{$[[A * B]]$}{Algorithmic Disjointness}{btmr, btml, intl, intr, orl, orr}
  \end{small}
  \begin{small}
    \centering
    \drules[typ]{$ [[G |- e dirflag A]] $}{Bidirectional Typing}{int, var, ann, app, sub, abs, switch}
  \end{small}
  \caption{Bottom-Like types, Algorithmic Disjointness and Typing for \cal.
    \snow{the var name in the third premise os TYP-SWITCH needs to be fixed} \baber{Done.} }
  \label{fig:union:disj-typ}
\end{figure}
\bruno{The syntax of typeof needs to be fixed, otherwise the variable ``x'' in the
typing rule appears from nowhere!}
\baber{Done, updated typeof to $[[switch e A e1 B e2]]$.}


%%%%%%%%%%%%%%%%%%%%%
%% Typing
%%%%%%%%%%%%%%%%%%%%%
\subsection{Typing}
\label{sec:union:typ}
The typing rules are shown at the bottom of \Cref{fig:union:disj-typ}.
We adopt bidirectional type-checking~\cite{} in our calculus.  There
are two typing modes in bidirectional typing: inference mode
($[[=>]]$) and checking mode ($[[<=]]$). In inference mode, the type of
an expression $[[e]]$ is inferred or calculated based upon certain
information available in the given context $[[G]]$.  While in checking
mode, an expression $[[e]]$ is checked against a given type $[[A]]$.
Typing rules are mostly standard. An integer
expression $[[i]]$ infers type $[[Int]]$ as stated in \rref{typ-int}.
\Rref{typ-var} states that a variable $[[x]]$ infers type $[[A]]$ if
$[[x]]$ has type $[[A]]$ in the given context. \Rref{typ-ann} states
if an expression $[[e]]$ checks against type $[[A]]$, then the
annotated expression $[[e:A]]$ infers type $[[A]]$.
\Rref{typ-app} type checks a function application and it is the
elimination rule for functions.
\snow{I think here we can say something about the annotated and raw
lambdas. The typing rule of application requires the function to
carry type information. A minor suggestion: can we make typing
a separate figure so that it can be close to the text here?}
\begin{comment}
Expression $[[e1]]$ has to
be a function expression and expression $[[e2]]$ has to check against
input type of $[[e1]]$.  An important point to notice in
\rref{typ-app} is $[[e1]]$ infers type $[[A -> B]]$. This may look
weird at the very first glance because lamda expressions ($[[\x.e]]$)
are not annotated in program expressions $[[e]]$ and it seems not
possible for lambda expression to infer its type.  To answer this
question, we emphasize the use of partial expressions $[[p]]$ and
values $[[v]]$.  Lambda expression is annotated in $[[p]]$ and so in
$[[v]]$ because values are defined as annotated partial expressions.
\end{comment}
\Rref{typ-sub} is the subsumption rule. It states that an expression
$[[e]]$ can be checked against any supertype of its inferred type.
\Rref{typ-abs} is the standard introduction rule for lambda
expressions. To check a lambda expression $[[\x.e]]$ against type $[[A
    -> B]]$, it is sufficient to check lambda body $[[e]]$ against the
output type $[[B]]$ in an extended context with parameter $[[x]]$ of
input type $[[A]]$.

The most interesting and novel typing rule is for
\emph{switch} expressions. Four conditions are necessary for typing
\emph{switch} expressions.
%The remaining conditions are standard for a calculus with
%union types and case expression and have been studied in various
%calculi (\baber{reference to calculi}).
The first condition ($[[G |-
    e <= A \/ B]]$) ensures that case expression $[[e]]$ is well-typed
and checks against type $[[A \/ B]]$. The next two conditions ensure that
branches of case expressions are well-typed and check against some type
$[[C]]$. An important point in these two conditions is that variables
$[[x]]$ and $[[y]]$ are, respectively, of type $[[A]]$ in first branch and of type $[[B]]$ in
second branch in the extended context. 
\snow{So they are exhaustive for all possible values of $e$. In other words,
at least one branch matches with the runtime type of $e$.}
From the last condition
$[[A *s B]]$, we guarantee that $[[A]]$ and $[[B]]$ are disjoint
types. This ensures that overlapping types for the branches of case expressions
are forbidden. Otherwise, overlapping types could lead to
non-deterministic results.
Since all the branches check against $[[C]]$, the whole
\emph{switch} expression checks against $[[C]]$.
\snow{Note that the two branches can have different return types.
For example, they infer to $A'$ and $B'$ respectively. In that case, the whole
expression can be checked by $[[A' \/ B']]$.}

\begin{comment}
\begin{figure}[t]
  \begin{small}
    \centering
    \drules[typ]{$ [[G |- e dirflag A]] $}{Bidirectional Typing}{int, var, ann, app, sub, abs, typeof}
  \end{small}
  \caption{Typing for \cal.}
  \label{fig:union:typ}
\end{figure}
\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%
%% Operations Semantics
%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Operational Semantics}
\label{sec:union:os}
The dynamics of \cal is defined by small-step operational semantics.
An important aspect of the semantics is that it is type-directed.
Type annotations are used to guide reduction, and the same term
with different type annotations can reduce in different ways.

\paragraph{The role of type annotations}
Before going
into the details of operational semantics, it is important to recall
the definition of pre-values, annotated values and values.
An integer expression $[[i]]$ is not a value unless annotated.
Non-annotated lambda expressions ($[[\x.e]]$) are values but cannot appear at left
side in function applications.
Only annotated values $[[w]]$ can appear at left side in function applications.
Annotated values consist of annotated pre-values. That is, it consists of
$[[i:A]]$ and $[[\x.e:(A1->B1):(A2->B2)]]$. This is
because that the orginal static type is tracked by the operational semantics.
Therefore, we can end up in a value such as $[[1 : Int]]$ or $[[1 : Top]]$,
and those two values can behave differently in some contexts.
\bruno{Give an example here}
For functions the static type is not enough and we also need the dynamic type
(which is the original type of the lambda).
For example, if we have:
$e = [[\x.x:Int->Int:(Int->Int)\/(Bool->Bool)]]$, then the static type of $e$ is
$[[(Int->Int)\/(Bool->Bool)]]$ and the, more precise, dynamic type is
$[[Int->Int]]$. If we use the following switch expression:

\bruno{example here with a switch}

The dynamic type is used to select the correct branch of the switch statement.
The presence of annotations with the static type, on the other hand,
ensures that types are preserved during substitution in
beta-reduction and \emph{switch} cases.

\paragraph{The Rules of the Operational Semantics}
\Cref{fig:union:os} shows operational semantics of \cal.
The operational semantics follows a call-by-value evaluation strategy.
\Rref{step-int} annotates integer expressions and makes them
values. \Rref{step-appl} reduces left expression of an application
unless it becomes an annotated value. \Rref{step-appr} works only if left
expression of an application is already reduced to annotated
value ($[[w]]$). We emphasize here again that non-annotated lamda expressions
($[[\x.e]]$) cannot appear at left side in applications.
Only annotated values can appear at left side in applications.
\snow{I think the reason behind the design deserves some explanation.}
Therefore, we have a condition of annotated value ($[[w]]$) at left
side of applications instead of value $[[v]]$.
\snow{Using $v$ instead of $w$ in this rule does not hurt anything.
Typing of application ensures it cannot be a raw lambda.}
\Rref{step-appr} then reduces right expression of application
to a value.

\Rref{step-beta} is the beta-reduction. It applies a dually
annotated lambda value $[[\x.e : A1 -> B1 : A2 -> B2]]$ to input
value $[[v]]$. Substitution replaces free occurences of variable
$[[x]]$ with $[[e1:A2:A1]]$.
Drop Static Type ($\rceil[[v]]\lceil$) drops the static type
from annotated values $[[p:A]]$ and returns $[[p]]$.
\snow{To me, it is weird to have space in a function's name.}
It does not change non-annotated values $[[\x.e]]$ and returns 
them as it is. Resultant expression $[[e1]]$ of ($\rceil[[v]]\lceil$)
is either a pre-value $[[p]]$ or $[[\x.e]]$.
Therefore, there are two cases to be considered in beta-reduction
during substitution. One for pre-values and other for $[[\x.e]]$.

For the first case, note that the annotation of the pre-value
$[[p]]$ changes to $[[p:A2:A1]]$ from $[[p:A]]$ during substitution.
$\rceil[[v]]\lceil$ drops $[[A]]$ from $[[p:A]]$ and returns $[[p]]$ 
as $[[e1]]$. Substitution then
substitutes free occurrences of variable $[[x]]$ with $[[e1:A2:A1]]$.
\snow{Question about the rule design: why drop $A$? Substituting $x$ by
$[[p:A:A2:A1]]$ should have the same effect as $[[p:A2:A1]]$.
On the other hand, why adding $[[A2]]$ after dropping $[[A]]$
instead of using $[[p:A1]]$?}
This is to keep the most specific type in the annotation. A substituted
expression is also annotated with both of the output types from
annotated lambda expression.
\snow{For the above sentence: We need double annotation here because the
result of function application might be a raw lambda, right?}
For the second case, that occurs when the
argument of a function is a non-annotatted lambda expression.
With bi-directional type-checking an expression such as:
($[[\f.f 1:(Int -> Int -> Int) : (Int -> Int -> Int)]]$)($[[\x.x]]$)
\snow{The type annotation is incorrect. Arrows are right-associative.}
\bruno{example here.} \baber{Done.}
is well-typed, since bi-directional type-checking propagates
type information to the arguments. Thus, the dynamic semantics
needs to deal with such programs. Substitution for second case goes
as for first case. Except that $\rceil[[v]]\lceil$ returns $[[\x.e]]$ as it is.
\Rref{step-ann}
reduces an annotated expression only if it is not an annotated value and $[[e]]$
reduces to some $[[e']]$. \Rref{step-rmann} drops inner
annotations. \Rref{step-lamann} adds one more type annotation with
lambda expressions having single type annotation to make them values.

\begin{comment}
\Rref{step-beta} deals with a special case, that occurs when the
argument of a function is a non-annotatted lambda expression.
With bi-directional type-checking an expression such as:
($[[\f.f 1:(Int -> Int -> Int) : (Int -> Int -> Int)]]$)($[[\x.x]]$)
\bruno{example here.} \baber{Done.}
is well-typed, since bi-directional type-checking propagates
type information to the arguments. Thus, the dynamic semantics
needs to deal with such programs.
We emphasize the fact that $[[\x.e]]$ is not a value in \cal.
The rule follows the same approach as
\rref{step-beta} except that both of the input types are kept with
$[[\x.e]]$ during substitution i.e $[[\x.e:A2:A1]]$. \Rref{step-ann}
reduces an annotated expression only if it is not a value and $[[e]]$
reduces to some $[[e']]$. \Rref{step-rmann} drops inner
annotations. \Rref{step-lamann} adds one more type annotation with
lambda expressions having single type annotation to make them values.
\end{comment}

\Rref{step-switch, step-switchl, step-switchr} deal with the reduction
of \emph{switch} expressions.
\snow{I have the same linking problem for switchl/r rules here as well.
Clicking them just bring me to the beginning of the pdf.}
\Rref{step-switch} reduces the case expression $[[e]]$ unless it
becomes a value of the form $[[p:D]]$.  
\snow{I suggest explain why the value cannot have a form of lambda here.}
\Rref{step-switchl} evaluates
the left branch of the \emph{switch} expression if the dynamic type of $[[p]]$ is
a subtype of type of left branch.  \Rref{step-switchr} evaluates the right
branch of the \emph{switch} expression if type of $[[e]]$ is subtype
of type of the right branch. The subtyping condition in \rref{step-switchl,
  step-switchr} is interesting and important to consider. It gives
freedom of various subtypes of $[[A]]$ and $[[B]]$ for a corresponding
branch instead of only type $[[A]]$ and type $[[B]]$. It is important
to note that types of left and right branches of a \emph{switch}
expression cannot overlap because of the disjointness constraint in
typing. \snow{Can refer to \rref{typ-switch}}
Programs with overlapping types in branches of \emph{switch}
expression will not type check in \cal.
\bruno{The following sentence is out-of-place. It should appear earlier
  when we talk about disjointness. Perhaps you can state the property
formally at that point.}
A natural property of \cal is
if type $[[A]]$ and type $[[B]]$ are two disjoint types, then subtypes
of $[[A]]$ are also disjoint to subtypes of $[[B]]$.

\paragraph{Dynamic Type} \baber{text for dropstatictype.} The dynamic semantics employs a simple
function that retrieves the dynamic type of a partial value. \snow{A pre-value?}
The definition
is shown in the lower part of \Cref{fig:union:os}.
$[[Int]]$ is returned when $[[p]]$ is an integer $[[i]]$ (\rref{findtype-int}).
Otherwise, for functions, the function annotation $[[A -> B]]$ is returned
(\rref{findtype-arrow}).

\begin{figure}[t]
  \begin{small}
    \centering
    \drules[step]{$[[e --> e']]$}{Operational Semantics}{int, appl, appr, beta, ann, rmann, lamann, switch, switchl, switchr}
  \end{small}
%  \begin{small}
%    \centering
%    \drules[findtype]{$[[findtype p A]]$}{FindType}{int, arrow}
%  \end{small}
  \bigskip
  %\begin{small}
  \begin{center}
  {\renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|llcl|}
      \hline
      Drop Static Type $\rceil$$[[v]]$$\lceil$ &  & & \\
     & $\rceil$$[[p:A]]$$\lceil$ & = & $[[p]]$ \\
     & $\rceil$$[[\x.e]]$$\lceil$ & = & $[[\x.e]]$ \\
      \hline
    \end{tabular} } \\
  \bigskip
  %\begin{small}
  {\renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|llcl|}
      \hline
      Dynamic Type $\rfloor$$[[p]]$$\lfloor$ &  & & \\
     & $\rfloor$$[[i]]$$\lfloor$ & = & $[[Int]]$ \\
     & $\rfloor$$[[\x.e: A -> B]]$$\lfloor$ & = & $[[A -> B]]$ \\
      \hline
    \end{tabular} }
    \end{center}
  \caption{Operational semantics, DropStaticType and DynamicType relation for \cal.}
  \label{fig:union:os}
\end{figure}
\bruno{Use a notation similar to LOS for FindType. Maybe for LOS you can use
  $\lfloor A \rfloor$ and for FindType you can use $|A|$. Also, rename FindType
into Dynamic Type.} 
\baber{Done. I changed the representation to function from inductive relation.
It looks more readable.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Type Safety and Determinism
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Type Safety and Determinism}
\label{sec:union:safety}
\cal is type sound and deterministic. In this section we discuss the
proofs of type safety and determinism for \cal. Type soundness is usually
considered as composition of type preservation and progress
lemma. Type preservation (\Cref{lemma:union:preservation}) states that
types are preserved during reduction. Progress
(\Cref{lemma:union:progress}) states that well typed programs never get
stuck.  A well typed expression $[[e]]$ is either a value or it can
take step to some other expression $[[e']]$. Therefore, preservation and progress
together ensure type safety.
\snow{preservation and progress should be theorems rather than lemmas.}
Substitution \Cref{lemma:union:substitution} is used in preservation and 
states that types are preserved during subtitution.
%We add one more choice in the conclusion
%of progress lemma to handle non-annotated lambda expressions
%($[[\x.e]]$). This last condition is necessary because the type system
%employs bi-directional type checking and unannotated lambdas (which are not values)
%can be well-typed in the checking mode.

\begin{lemma}[Type Preservation]
\label{lemma:union:preservation}
  If \ $[[G |- e dirflag A]]$ and $[[e --> e']]$ then $[[G |- e' dirflag A]]$.
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on typing relation and subsequent inverting reduction relation.
  \begin{itemize}
    \item Cases \rref{typ-int, typ-var, typ-sub, typ-abs} are trivial to prove.
    \item Case \rref{typ-ann} requires helping \cref{lemma:union:check-pexpr-ann}.
    \item Case \rref{typ-app} requires helping \cref{lemma:union:pexpr-check-sub}
          and substitution \cref{lemma:union:substitution} for beta reduction.
    \item Case \rref{typ-typeof} requires substitution \cref{lemma:union:substitution}.
  \end{itemize}
\end{proof}

\baber{ToDo: change name of helping lemmas.}

\begin{lemma}[check-pexpr-ann]
\label{lemma:union:check-pexpr-ann}
  If \ $[[G |- p:C <= A]]$ \ then \ $[[G |- p <= A]]$.
\end{lemma}

\begin{lemma}[pexpr-check-sub]
\label{lemma:union:pexpr-check-sub}
  If \ $[[G |- p <= A]]$ \ and \ $[[A <: B]]$ \ then \ $[[G |- p <= B]]$.
\end{lemma}
\end{comment}

\begin{lemma}[Progress]
\label{lemma:union:progress}
If \ $[[ [] |- e dirflag A]]$ then
 \begin{enumerate}
  \item either $[[e]]$ is a value.
  \item or $[[e]]$ can take a step to $[[e']]$.
  \end{enumerate}
\end{lemma}

\begin{lemma}[Substitution]
\label{lemma:union:substitution}
  If \ $[[G, x:B , G1 |- e dirflag A]]$ \ and \ $[[G |- e' => B]]$
  then \ $[[G, G1 |- e [ x ~> e' ] dirflag A]]$
\end{lemma}

\begin{comment}
\begin{proof}
By induction on typing relation.
  \begin{itemize}
    \item Cases \rref{typ-int, typ-var, typ-app, typ-sub, typ-abs} are trivial to prove.
    \item Case \rref{typ-anno} requires \cref{lemma:union:value-not-value}.
    \item Case \rref{typ-typeof} requires
    \cref{lemma:union:check-pexpr-ann,lemma:union:check-or-typ,lemma:union:pexpr-inf-typ}.
  \end{itemize}
\end{proof}

\begin{lemma}[Value Decidability]
\label{lemma:union:value-not-value}
$\forall$ $[[e]]$, \ value \ $[[e]]$ \ $\vee$ \ $\neg$ value \ $[[e]]$.
\end{lemma}

\begin{lemma}[check-or-typ]
\label{lemma:union:check-or-typ}
If \ $[[A *s B]]$ \ and \ $[[G |- p <= A \/ B]]$ \ then:
  \begin{enumerate}
    \item either \ $[[G |- p <= A]]$
    \item or \ $[[G |- p <= B]]$
  \end{enumerate}
\end{lemma}

\begin{lemma}[pexpr-inf-typ]
\label{lemma:union:pexpr-inf-typ}
If \ $[[G |- p <= A]]$ \ then:
  \begin{enumerate}
  \item $\exists$ $[[B]]$, \ $[[B <: A]]$
  \item and \ $[[G |- p => B]]$
  \end{enumerate}
\end{lemma}
\end{comment}

Determinism (\Cref{lemma:union:determinism}) is also a
critical property for our calculus. Determinism ensures that a program will always
produce the same unique result.
Determinism guarantees that switch expressions are not order-sensitive:
because the calculus is deterministic this implies that \rref{Step-Switchl,Step-Switchr}
can never be apply for the same well-typed expression.

\begin{lemma}[Determinism]
\label{lemma:union:determinism}
  If \ $[[G |- e dirflag A]]$ and \ $[[e --> e1]]$ and \ $[[e --> e2]]$ then $[[e1]]$ = $[[e2]]$.
\end{lemma}

\begin{comment}
\begin{proof}
  By induction on first reduction relation and inverting second reduction relation subsequently.
  All cases are trivial to solve by simple inversions except:
  \begin{itemize}
    \item Case \rref{typ-typeof} requires \cref{lemma:union:check-both-disj-false}.
  \end{itemize}
\end{proof}

\begin{lemma}[check-both-disj-false]
\label{lemma:union:check-both-disj-false}
If \ $[[A *s B]]$ \ and \ $[[G |- p <= A]]$ \ and \ $[[G |- p <= B]]$ \ then \ False.
\end{lemma}
\end{comment}

\baber{Again, should we show the property that a term cannot be checked against two disjoint types?}
\bruno{I think you can and connect that to the last point in the text above, perhaps.}

\snow{I think substitution lemma should be presented before preservation because
the later depends one the former. And if you are going to state the above lemma,
maybe you can group it with the substitution lemma. They are both irrelevant to
reduction but only related to typing.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Discussion on Disjointness
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{An Alternative Specification for Disjointness}
\label{sec:union:discussion}
\snow{I feel the reason and consequence are flipped here. 
The alternative spec definitely equals to the previous one
because we define ``ordinary types" to satisfy:
1) no bottom-like types are ordinary;
2) any type must have an ordinary subtype if it is not bottom-like.
Or we need to provide some intuition for ordinary types themselves.}

The current definition of disjointness (\cref{def:union:disj}) is inspired
by work on disjoint intersection types~\cite{oliveira2016disjoint}. This definition works well
for the calculus presented in this section. However it is not the only
possible formulation of disjointness.
An equivalent formulation of disjointness is shown in Figure~\ref{fig:union:ord}.
This definition relies on the notion of \emph{ordinary types}, which are essentially
those types that are primitive, such as integers and functions.
\bruno{Drop the Ord Top from the figure}. \baber{Done.}
The new disjointness definition (\Cref{def:union:disj1}) states that two
types are disjoint if they do not have common ordinary subtypes.

It is important to establish the fact that definition
\Cref{def:union:disj1} is indeed equivalent to our current
definition. We prove equivalence of \Cref{def:union:disj} and
\Cref{def:union:disj1} to establish this fact.

\begin{lemma}[Disjointness Equivalence]
A $*_{s}$ B $\longleftrightarrow$ A $*_{s1}$ B.
\end{lemma}

\begin{figure}
    \centering
    \drules[ord]{$[[ordinary A]]$}{Ordinary Types}{int, arrow}
  \medskip
  \begin{definition}
    \centering
    A $*_{s1}$ B $\Coloneqq$ $\forall$ C, $[[ordinary C]]$ $\rightarrow$ $\neg$ ($[[C <: A]]$ $\wedge$ $[[C <: B]]$)
    \label{def:union:disj1}
  \end{definition}
  \caption{Updated disjointness and ordinary types for \cal.
    \snow{I think there is no need to make figure small
    unless we are going to exceed the page limit.} \baber{Sure, I fixed that.}}
  \label{fig:union:ord}
\end{figure}

Definition \Cref{def:union:disj1} will play an important role in the
calculus presented in Section~\ref{sec:inter}.
